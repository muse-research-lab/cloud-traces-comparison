{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtd.input import CsvFullReader\n",
    "\n",
    "from gtd.preprocessor import TimeConfigurator, Padder, TaskNormalizer, Cropper, OutlierHandler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.utils.metric import distance_metric\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.encoder import cluster_encoder\n",
    "\n",
    "from gtd.comparator.calculators import l1_img, l2_img, dtwl2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "colors = ['gainsboro', 'lightgray', 'grey']\n",
    "hatches = ['///', '', '', '..', '\\\\', 'X', 'o', '+']\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=colors)\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = CsvFullReader(input_dir='./input-sim/', structured=True, columns=['time', 'avg_cpu_usage']).read_input()\n",
    "inp_ = CsvFullReader(input_dir='./input-dis/', structured=True, columns=['time', 'avg_cpu_usage']).read_input()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1024\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_1 = TimeConfigurator(time_col='time', time_unit='us', freq='5min').run(inp)\n",
    "inp_1_ = TimeConfigurator(time_col='time', time_unit='us', freq='5min').run(inp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_2 = Padder(freq='5min').run(inp_1)\n",
    "inp_2_ = Padder(freq='5min').run(inp_1_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp_2_1 = OutlierHandler(col='avg_cpu_usage', llim=0.01, ulim=0.99).run(inp_2)\n",
    "#inp_2_1_ = OutlierHandler(col='avg_cpu_usage', llim=0.01, ulim=0.99).run(inp_2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_3 = Cropper(llim=offset, ulim=offset+size).run(inp_2)\n",
    "inp_3_ = Cropper(llim=offset, ulim=offset+size).run(inp_2_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_end = TaskNormalizer(col='avg_cpu_usage').run(inp_3)\n",
    "inp_end_ = TaskNormalizer(col='avg_cpu_usage').run(inp_3_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in inp_end.get_tasks():\n",
    "    x = task.get_fraction_by_idx(0).data.index\n",
    "    y = task.get_fraction_by_idx(0).data['avg_cpu_usage']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 3))\n",
    "    \n",
    "    plt.xticks(size = 30)\n",
    "    plt.yticks(size = 30)\n",
    "\n",
    "    x_ticks = [x[0], x[287], x[575], x[863]]\n",
    "\n",
    "    x_labels = [0, 1, 2, 3]\n",
    "\n",
    "    ax.plot(x, y, color='black', label=f\"Job {str(task.job_id)[:3]}\")\n",
    "\n",
    "    ax.grid(False)\n",
    "    \n",
    "    plt.xticks(ticks=x_ticks, labels=x_labels)\n",
    "    \n",
    "    if task.job_id == 399444405700:\n",
    "        ax.set_xlabel('Time (days)',  size = 35)\n",
    "    ax.set_ylabel('CPU Usage',  size = 35, loc='center')\n",
    "\n",
    "    ax.legend(loc='lower right', bbox_to_anchor=(1.01, 0.9), fontsize=35, handlelength=0, handletextpad=0, frameon=False)\n",
    "\n",
    "    fig.savefig(f'./output/tasks-sim/{task.job_id}-{task.idx}.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in inp_end_.get_tasks():\n",
    "    x = task.get_fraction_by_idx(0).data.index\n",
    "    y = task.get_fraction_by_idx(0).data['avg_cpu_usage']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 3))\n",
    "    \n",
    "    plt.xticks(size = 30)\n",
    "    plt.yticks(size = 30)\n",
    "    \n",
    "    x_ticks = [x[0], x[287], x[575], x[863]]\n",
    "\n",
    "    x_labels = [0, 1, 2, 3]\n",
    "\n",
    "    ax.plot(x, y, color='black', label=f\"Task {str(task.idx)}\")\n",
    "\n",
    "    ax.grid(False)\n",
    "\n",
    "    plt.xticks(ticks=x_ticks, labels=x_labels)\n",
    "    \n",
    "    if task.idx == 61:\n",
    "        ax.set_xlabel('Time (days)',  size = 35)\n",
    "    ax.set_ylabel('CPU Usage',  size = 35, loc='center')\n",
    "\n",
    "    ax.legend(loc='lower right', bbox_to_anchor=(1.01, 0.9), fontsize=35, handlelength=0, handletextpad=0, frameon=False)\n",
    "\n",
    "    fig.savefig(f'./output/tasks-dis/{task.job_id}-{task.idx}.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "labels = []\n",
    "labels_idxs = []\n",
    "for task in inp_end.get_tasks():\n",
    "\n",
    "    task_data = task.get_fraction_by_idx(0).data['avg_cpu_usage'].to_numpy(copy=True)\n",
    "    \n",
    "    lst.append(task_data)\n",
    "    labels.append(task.job_id)\n",
    "    labels_idxs.append(task.idx)\n",
    "\n",
    "df = pd.DataFrame(lst)\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_centers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, dist_func in zip(['L1', 'L2', 'DTW'], [l1_img, l2_img, dtwl2]):\n",
    "    for n_clusters in range(6, 7):\n",
    "        initial_centers = kmeans_plusplus_initializer(data, n_clusters, random_state=42).initialize()\n",
    "\n",
    "        instanceKm = kmeans(data, initial_centers=initial_centers, metric=distance_metric(1000, func=dist_func))\n",
    "\n",
    "        instanceKm.process()\n",
    "\n",
    "        pyClusters = instanceKm.get_clusters()\n",
    "        pyCenters = instanceKm.get_centers()\n",
    "\n",
    "        clusters_centers[metric] = (pyClusters, pyCenters)\n",
    "\n",
    "        pyEncoding = instanceKm.get_cluster_encoding()\n",
    "        pyEncoder = cluster_encoder(pyEncoding, pyClusters, data)\n",
    "        pyLabels = pyEncoder.set_encoding(0).get_clusters()\n",
    "\n",
    "        clusters = {}\n",
    "\n",
    "        for i in range(n_clusters):\n",
    "            clusters[i] = {}\n",
    "\n",
    "            for job_id in set(labels):\n",
    "                clusters[i][job_id] = 0\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            clusters[pyLabels[i]][labels[i]] = clusters[pyLabels[i]][labels[i]] + 1\n",
    "\n",
    "        for cluster, vals in clusters.items():\n",
    "            tmp = []\n",
    "            for _, val in sorted(vals.items()):\n",
    "                tmp.append(val)\n",
    "\n",
    "            clusters[cluster] = tmp\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10/2,6/2))\n",
    "\n",
    "        plt.xticks(size = 18)\n",
    "        plt.yticks(size = 18)\n",
    "\n",
    "        jobs = [str(x)[:3] for x in sorted(set(labels))]\n",
    "        bottom = np.zeros(len(jobs))\n",
    "\n",
    "        lines = []\n",
    "        leg_labels = []\n",
    "        i = 0\n",
    "        for cluster_id, cnts in clusters.items():\n",
    "            line = ax.bar(jobs, cnts, 0.5, label=cluster_id, bottom=bottom, hatch=hatches[i])\n",
    "\n",
    "            lines.append(line)\n",
    "            leg_labels.append(cluster_id)\n",
    "\n",
    "            i += 1\n",
    "            bottom += cnts\n",
    "\n",
    "        ax.set_xlabel('Jobs', size = 20)\n",
    "        ax.set_ylabel('Number of Tasks', size = 20)\n",
    "\n",
    "        # ax.legend(loc=2, bbox_to_anchor=(1, 1), title=\"Cluster\", fontsize=30, title_fontsize=30)\n",
    "        ax.set_ylim(0, 10.5)\n",
    "        ax.set_yticks(range(0, 11))\n",
    "\n",
    "        ax.yaxis.grid()\n",
    "\n",
    "        fig.savefig(f'./output/clusters-sim/numeric-{metric}-{n_clusters}.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        legendFig = plt.figure()\n",
    "        legendFig.legend(lines, leg_labels, loc='center', title=\"Cluster\", fontsize=15, title_fontsize=18, ncols=6)\n",
    "        legendFig.savefig('./output/numeric-legend.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_job_map = {\n",
    "    \"L1\": {\n",
    "        0: 91724979887,\n",
    "        1: 382417448240,\n",
    "        2: 113812204462,\n",
    "        3: 374877055556,\n",
    "        4: 399444405700,\n",
    "        5: 380263806889\n",
    "    },\n",
    "    \"L2\": {\n",
    "        0: 91724979887,\n",
    "        1: 382417448240,\n",
    "        2: 113812204462,\n",
    "        3: 374877055556,\n",
    "        4: 399444405700,\n",
    "        5: 380263806889\n",
    "    },\n",
    "    \"DTW\": {\n",
    "        0: 91724979887,\n",
    "        1: 382417448240,\n",
    "        2: 113812204462,\n",
    "        3: 374877055556,\n",
    "        4: 399444405700,\n",
    "        5: 380263806889\n",
    "    },\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissimilar Tasks - Time Shifted Tasks (Job 113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric, dist_func in zip(['L1', 'L2', 'DTW'], [l1_img, l2_img, dtwl2]):\n",
    "    centers = clusters_centers[metric][1]\n",
    "    \n",
    "    cluster_cnts = [0 for i in range(len(centers))]\n",
    "\n",
    "    real_cnt = 0\n",
    "    cluster_cnts_real = [[0 for i in range(len(centers))] for i in range(5)]\n",
    "    labels_real = []\n",
    "    hatches = ['///', '', '..', '\\\\', 'x',]\n",
    "    \n",
    "    x_labels = [str(val)[:3] for _, val in sorted(cluster_to_job_map[metric].items(), key=lambda item: item[1])]\n",
    "\n",
    "    for task in inp_end_.get_tasks():\n",
    "        task_data = task.get_fraction_by_idx(0).data['avg_cpu_usage'].to_numpy(copy=True)\n",
    "        \n",
    "        distances = []\n",
    "        for cluster_id, center in enumerate(centers):\n",
    "            distances.append(dist_func(task_data, np.array(center)))\n",
    "\n",
    "        # Task vs Cluster Centers\n",
    "        fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "        x = np.arange(len(distances))\n",
    "        y = [distances[key] for key, val in sorted(cluster_to_job_map[metric].items(), key=lambda item: item[1])]\n",
    "\n",
    "        bars = ax.bar(x, y)\n",
    "\n",
    "        closest_cluster_id = np.argmin(distances)\n",
    "        for i, item in enumerate(sorted(cluster_to_job_map[metric].items(), key=lambda item: item[1])):\n",
    "            if item[0] == closest_cluster_id:\n",
    "                bars[i].set_color('grey')\n",
    "                break\n",
    "\n",
    "        ax.set_xticks(x, x_labels)\n",
    "\n",
    "        ax.set_xlabel(\"Jobs\")\n",
    "        ax.set_ylabel(\"Distance\")\n",
    "        ax.set_title(f\"Task {task.idx} vs Cluster Center of each Job\")\n",
    "\n",
    "        fig.savefig(f'./output/clusters-distances/numeric-{metric}-{task.idx}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "        plt.close()\n",
    "\n",
    "        if task.idx < 100:\n",
    "            print(task.idx, \"->\", cluster_to_job_map[metric][closest_cluster_id])\n",
    "\n",
    "            labels_real.append(task.idx)\n",
    "            cluster_cnts_real[real_cnt][closest_cluster_id] = 1\n",
    "            real_cnt = real_cnt + 1\n",
    "        else:\n",
    "            cluster_cnts[closest_cluster_id] = cluster_cnts[closest_cluster_id] + 1\n",
    "\n",
    "    # Aggregated Clustering of Dissimilar Tasks\n",
    "    fig, ax = plt.subplots(figsize=(10/2,6/2))\n",
    "\n",
    "    plt.xticks(size = 18)\n",
    "    plt.yticks(size = 18)\n",
    "    \n",
    "    lines = []\n",
    "    leg_labels = []\n",
    "    x = np.arange(len(cluster_cnts))\n",
    "    y = [cluster_cnts[key] for key, val in sorted(cluster_to_job_map[metric].items(), key=lambda item: item[1])]\n",
    "\n",
    "    line = ax.bar(x, y, color='grey', label=\"Synthetic\")\n",
    "\n",
    "    lines.append(line)\n",
    "    leg_labels.append(\"Synthetic\")\n",
    "\n",
    "    bottom = np.array(y)\n",
    "    for i, cnts in enumerate(cluster_cnts_real):\n",
    "        y_real = [cnts[key] for key, val in sorted(cluster_to_job_map[metric].items(), key=lambda item: item[1])]\n",
    "        line = ax.bar(x, y_real, color='lightgray', bottom=bottom, label=f\"Task {labels_real[i]}\", hatch=hatches[i])\n",
    "\n",
    "        lines.append(line)\n",
    "        leg_labels.append(f\"Task {labels_real[i]}\")\n",
    "\n",
    "        bottom = bottom + np.array(y_real)\n",
    "\n",
    "    ax.set_xticks(x, x_labels)\n",
    "\n",
    "    # ax.set_title(\"Clustering of Dissimilar Tasks of Job 113\")\n",
    "    ax.set_xlabel('Jobs', size = 20)\n",
    "    ax.set_ylabel('Number of Tasks', size = 20)\n",
    "\n",
    "    ax.set_ylim(0, 20.5)\n",
    "    ax.set_yticks([2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n",
    "\n",
    "    ax.yaxis.grid()\n",
    "    \n",
    "    # ax.legend(loc=2, bbox_to_anchor=(1, 1), fontsize=30)\n",
    "    \n",
    "    fig.savefig(f'./output/clusters-dis/numeric-{metric}-{n_clusters}.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    legendFig = plt.figure()\n",
    "    legendFig.legend(lines, leg_labels, loc='center', fontsize=15, ncols=3)\n",
    "    legendFig.savefig('./output/numeric-legend-dis.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de2b92284a4d8d056cfce7416b62cb768d0d6ca40acb916a934b57019dc69449"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
